{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory_dir = r\"C:\\Users\\Alan\\Documents\\hybridfactory\"\n",
    "\n",
    "os.chdir(factory_dir)\n",
    "sys.path.insert(0, factory_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import factory.io.raw\n",
    "import factory.io.gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = importlib.import_module(\"npix-gen-20180510\")\n",
    "probe = importlib.import_module(f\"factory.probes.{params.probe_type}\")\n",
    "\n",
    "params.verbose = True\n",
    "params.copy = False\n",
    "\n",
    "SPIKE_LIMIT = 25000\n",
    "\n",
    "np.random.seed(params.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log(msg, stdout, in_progress=False):\n",
    "    end = \" ... \" if in_progress else \"\\n\"\n",
    "\n",
    "    if stdout:\n",
    "        print(msg, end=end)\n",
    "\n",
    "\n",
    "def _user_dialog(msg, options=(\"y\", \"n\"), default_option=\"n\"):\n",
    "    default_option = default_option.lower()\n",
    "    options = [o.lower() for o in options]\n",
    "    assert default_option in options\n",
    "\n",
    "    options.insert(options.index(default_option), default_option.upper())\n",
    "    options.remove(default_option)\n",
    "\n",
    "    print(msg, end=\" \")\n",
    "    choice = input(f\"[{'/'.join(options)}] \").strip().lower()\n",
    "\n",
    "    iters = 0\n",
    "    while choice and choice not in list(map(lambda x: x.lower(), options)) and iters < 3:\n",
    "        iters += 1\n",
    "        choice = input(f\"[{'/'.join(options)}] \").strip().lower()\n",
    "\n",
    "    if not choice or choice not in list(map(lambda x: x.lower(), options)):\n",
    "        choice = default_option\n",
    "\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_source_target(params, probe):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : module\n",
    "        Session parameters.\n",
    "    probe : module\n",
    "        Probe parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    source : numpy.memmap\n",
    "        Memory map of source data file.\n",
    "    target : numpy.memmap\n",
    "        Memory map of target data file.\n",
    "    \"\"\"\n",
    "\n",
    "    if op.isfile(params.raw_target_file) and not params.overwrite:\n",
    "        if _user_dialog(f\"Target file {params.raw_target_file} exists! Overwrite?\") == \"y\":\n",
    "            params.overwrite = True\n",
    "        else:\n",
    "            print(\"aborting\")\n",
    "            return\n",
    "\n",
    "    if params.copy:\n",
    "        _log(f\"Copying {params.raw_source_file} to {params.raw_target_file}\", params.verbose, in_progress=True)\n",
    "        shutil.copy2(params.raw_source_file, params.raw_target_file)\n",
    "        _log(\"done\", params.verbose)\n",
    "\n",
    "    file_size_bytes = op.getsize(params.raw_source_file)\n",
    "    byte_count = np.dtype(params.data_type).itemsize  # number of bytes in data type\n",
    "    nrows = probe.NCHANS + params.extra_channels\n",
    "    ncols = file_size_bytes // (nrows * byte_count)\n",
    "\n",
    "    params.num_samples = ncols\n",
    "\n",
    "    source = np.memmap(params.raw_source_file, dtype=params.data_type, offset=params.offset, mode=\"r\",\n",
    "                       shape=(nrows, ncols), order=\"F\")\n",
    "    target = np.memmap(params.raw_target_file, dtype=params.data_type, offset=params.offset, mode=\"r+\",\n",
    "                       shape=(nrows, ncols), order=\"F\")\n",
    "\n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_artificial_events(source, params, probe, unit_times):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source : numpy.memmap\n",
    "        Memory map of data file.\n",
    "    params : module\n",
    "        Session parameters.\n",
    "    probe : module\n",
    "        Probe parameters.\n",
    "    unit_times : numpy.ndarray\n",
    "        Array of firing times for this unit.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    art_events : numpy.ndarray\n",
    "        Tensor, num_channels x num_samples x num_events, constructed by `generator`.\n",
    "    channels : numpy.ndarray\n",
    "        Channels on which the original events occur.\n",
    "    \"\"\"\n",
    "\n",
    "    # e.g., factory.generators.steinmetz\n",
    "    generator = importlib.import_module(f\"factory.generators.{params.generator_type}\")\n",
    "    art_events, channels = generator.generate(source, params, probe, unit_times)\n",
    "\n",
    "    return art_events, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_artificial_events(source, params, probe, unit_times):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source : numpy.memmap\n",
    "        Memory map of data file.\n",
    "    params : module\n",
    "        Session parameters.\n",
    "    probe : module\n",
    "        Probe parameters.\n",
    "    unit_times : numpy.ndarray\n",
    "        Array of firing times for this unit.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    art_events : numpy.ndarray\n",
    "        Tensor, num_channels x num_samples x num_events, constructed by `generator`.\n",
    "    channels : numpy.ndarray\n",
    "        Channels on which the original events occur.\n",
    "    \"\"\"\n",
    "\n",
    "    # e.g., factory.generators.steinmetz\n",
    "    generator = importlib.import_module(f\"factory.generators.{params.generator_type}\")\n",
    "    art_events, channels = generator.generate(source, params, probe, unit_times)\n",
    "\n",
    "    return art_events, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_channels(channels, params, probe):\n",
    "    \"\"\"Shift a subset of the channels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : numpy.ndarray\n",
    "        Input channels to be shifted.\n",
    "    params : module\n",
    "        Session parameters.\n",
    "    probe : module\n",
    "        Probe parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    shifted_channels : numpy.ndarray or None\n",
    "        Channels shifted by some constant factor.\n",
    "    \"\"\"\n",
    "\n",
    "    # inverse_channel_map[probe.channel_map] == [1, 2, ..., probe.channel_map.size - 1]\n",
    "    inverse_channel_map = np.zeros(probe.channel_map.size, dtype=np.int64)\n",
    "    inverse_channel_map[probe.channel_map] = np.arange(probe.channel_map.size)\n",
    "\n",
    "    # make sure our shifted channels fall in the range [0, probe.channel_map)\n",
    "    if inverse_channel_map[channels].max() < probe.channel_map.size - params.channel_shift:\n",
    "        shifted_channels = probe.channel_map[inverse_channel_map[channels] + params.channel_shift]\n",
    "    else:\n",
    "        shifted_channels = probe.channel_map[inverse_channel_map[channels] - params.channel_shift]\n",
    "\n",
    "    try:\n",
    "        assert shifted_channels.min() > -1 and shifted_channels.max() < probe.channel_map.size\n",
    "    except AssertionError:\n",
    "        _log(f\"channel shift of {params.channel_shift} places events outside of probe range\", params.verbose)\n",
    "        return None\n",
    "\n",
    "    # make sure our shifted channels don't land on unconnected channels\n",
    "    try:\n",
    "        assert np.intersect1d(shifted_channels, probe.channel_map[~probe.connected]).size == 0\n",
    "    except AssertionError:\n",
    "        _log(f\"channel shift of {params.channel_shift} places events on unconnected channels\", params.verbose)\n",
    "        return None\n",
    "\n",
    "    # make sure our shifted channels don't alter spatial relationships\n",
    "    channel_distance = scipy.spatial.distance.pdist(probe.channel_positions[inverse_channel_map[channels], :])\n",
    "    shifted_distance = scipy.spatial.distance.pdist(probe.channel_positions[inverse_channel_map[shifted_channels], :])\n",
    "\n",
    "    try:\n",
    "        assert np.isclose(channel_distance, shifted_distance).all()\n",
    "    except AssertionError:\n",
    "        _log(f\"channel shift of {params.channel_shift} alters spatial relationship between channels\", params.verbose)\n",
    "        return None\n",
    "\n",
    "    return shifted_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter_events(unit_times, params):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    unit_times : numpy.ndarray\n",
    "        Firing times for this unit, to be jittered.\n",
    "    params : module\n",
    "        Session parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    jittered_times : numpy.ndarray\n",
    "        Jittered firing times for artificial events.\n",
    "    \"\"\"\n",
    "\n",
    "    isi_samples = params.sample_rate // 1000  # number of samples in 1 ms\n",
    "    # normally-distributed jitter factor, with an absmin of `isi_samples`\n",
    "    jitter1 = isi_samples + np.abs(np.random.normal(loc=0, scale=params.time_jitter // 2, size=unit_times.size // 2))\n",
    "    jitter2 = -(isi_samples + np.abs(isi_samples + np.random.normal(loc=0, scale=params.time_jitter // 2,\n",
    "                                                                    size=unit_times.size - jitter1.size)))\n",
    "\n",
    "    # leaves a window of 2 ms around `unit_times` so units don't fire right on top of each other\n",
    "    jitter = np.random.permutation(np.hstack((jitter1, jitter2))).astype(unit_times.dtype)\n",
    "\n",
    "    jittered_times = unit_times + jitter\n",
    "\n",
    "    try:\n",
    "        assert (jittered_times - params.samples_before > 0).all() and \\\n",
    "               (jittered_times + params.samples_after < params.num_samples).all()\n",
    "    except AssertionError:\n",
    "        _log(f\"time jitter of {params.time_jitter} and sample window places events outside of sample range\",\n",
    "             params.verbose)\n",
    "        return None\n",
    "\n",
    "    return jittered_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "io = importlib.import_module(f\"factory.io.{params.output_type}\")  # e.g., factory.io.phy, factory.io.kilosort, ...\n",
    "event_times = io.load_event_times(params.data_directory)\n",
    "event_clusters = io.load_event_clusters(params.data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_channels = []\n",
    "gt_times = []\n",
    "gt_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying F:\\CortexLab\\singlePhase3\\data\\Hopkins_20160722_g0_t0.imec.ap_CAR.bin to C:\\Users\\Alan\\Documents\\Data\\npix-hybrid\\Hopkins_20160722_g0_t0.imec.ap_CAR.GT.bin ... done\n",
      "Generating ground truth for unit 18 ... done\n",
      "Shifting channels ... channel shift of 20 places events on unconnected channels\n",
      "Generating ground truth for unit 36 ... done\n",
      "Shifting channels ... done\n",
      "Jittering events ... done\n",
      "Writing events to file ... done\n",
      "Generating ground truth for unit 83 ... done\n",
      "Shifting channels ... done\n",
      "Jittering events ... done\n",
      "Writing events to file ... done\n",
      "Generating ground truth for unit 199 ... no waveforms crossed threshold; skipping\n",
      "Generating ground truth for unit 243 ... done\n",
      "Shifting channels ... done\n",
      "Jittering events ... done\n",
      "Writing events to file ... done\n",
      "Generating ground truth for unit 267 ... done\n",
      "Shifting channels ... channel shift of 20 places events on unconnected channels\n",
      "Generating ground truth for unit 283 ... no waveforms crossed threshold; skipping\n",
      "Generating ground truth for unit 464 ... done\n",
      "Shifting channels ... done\n",
      "Jittering events ... done\n",
      "Writing events to file ... done\n",
      "Generating ground truth for unit 1074 ... done\n",
      "Shifting channels ... done\n",
      "Jittering events ... done\n",
      "Writing events to file ... done\n",
      "Generating ground truth for unit 1159 ... done\n",
      "Shifting channels ... done\n",
      "Jittering events ... done\n",
      "Writing events to file ... done\n"
     ]
    }
   ],
   "source": [
    "source, target = copy_source_target(params, probe)\n",
    "\n",
    "for unit_id in params.ground_truth_units:\n",
    "    unit_times = event_times[event_clusters == unit_id]\n",
    "    \n",
    "    if unit_times.size > SPIKE_LIMIT:\n",
    "        unit_times = np.random.choice(unit_times, size=SPIKE_LIMIT, replace=False)\n",
    "\n",
    "    # generate artificial events for this unit\n",
    "    _log(f\"Generating ground truth for unit {unit_id}\", params.verbose, in_progress=True)\n",
    "    art_events, channel_subset = construct_artificial_events(source, params, probe, unit_times)\n",
    "    if art_events is None:\n",
    "        _log(\"no waveforms crossed threshold; skipping\", params.verbose)\n",
    "        continue\n",
    "\n",
    "    _log(\"done\", params.verbose)\n",
    "\n",
    "    # shift channels\n",
    "    _log(\"Shifting channels\", params.verbose, in_progress=True)\n",
    "    shifted_channels = shift_channels(channel_subset, params, probe)\n",
    "\n",
    "    if shifted_channels is None:\n",
    "        continue  # cause is logged in `shift_channels`\n",
    "\n",
    "    _log(\"done\", params.verbose)\n",
    "\n",
    "    # jitter events\n",
    "    _log(\"Jittering events\", params.verbose, in_progress=True)\n",
    "    jittered_times = jitter_events(unit_times, params)\n",
    "    _log(\"done\", params.verbose)\n",
    "\n",
    "    if jittered_times is None:\n",
    "        continue\n",
    "\n",
    "    # write to file\n",
    "    _log(\"Writing events to file\", params.verbose, in_progress=True)\n",
    "    for i, jittered_center in enumerate(jittered_times):\n",
    "        jittered_samples = np.arange(jittered_center - params.samples_before,\n",
    "                                     jittered_center + params.samples_after + 1)\n",
    "\n",
    "        shifted_window = factory.io.raw.read_roi(target, shifted_channels, jittered_samples)\n",
    "        perturbed_data = shifted_window + art_events[:, :, i]\n",
    "\n",
    "        factory.io.raw.write_roi(target, shifted_channels, jittered_samples, perturbed_data)\n",
    "\n",
    "    _log(\"done\", params.verbose)\n",
    "\n",
    "    cc_indices = np.abs(art_events).max(axis=1).argmax(axis=0)  # num_events\n",
    "    center_channels = shifted_channels[cc_indices] + 1\n",
    "\n",
    "    gt_channels.append(center_channels)\n",
    "    gt_times.append(jittered_times)\n",
    "    gt_labels.append(unit_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firing times and labels saved to C:\\Users\\Alan\\Documents\\Data\\npix-hybrid\\firings_true.npy.\n"
     ]
    }
   ],
   "source": [
    "dirname = op.dirname(params.raw_target_file)\n",
    "\n",
    "# save ground-truth units for validation\n",
    "filename = factory.io.gt.save_gt_units(dirname, gt_channels, gt_times, gt_labels)\n",
    "_log(f\"Firing times and labels saved to {filename}.\", params.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "firings_true = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 57816)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firings_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
